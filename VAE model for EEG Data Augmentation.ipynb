{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eea743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, Dense, Lambda, Reshape, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf5ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = r'bci_iv_2a_data/A01/train/0/'     #data directory\n",
    "\n",
    "train_dataset = []\n",
    "train_label = []\n",
    "\n",
    "test_dataset = []\n",
    "test_label = []\n",
    "\n",
    "files = os.listdir(direc)\n",
    "for j, name in enumerate(files):\n",
    "    filename = glob.glob(direc + '/'+ name)\n",
    "    df = pd.read_csv(filename[0], index_col=None, header=None)\n",
    "    df = df.drop(0, axis=1)     #dropping column of channel names\n",
    "    df = df.iloc[:,0:1000]      #taking 1000 timesteps\n",
    "    train_dataset.append(np.array(df))\n",
    "            \n",
    "\n",
    "\n",
    "train_dataset = np.array(train_dataset)\n",
    "train_data = np.expand_dims(train_dataset,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1078002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80:20 training-validation split\n",
    "X_train, X_test = train_test_split(train_data,  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model\n",
    "input_shape=(X_train.shape[1:])\n",
    "batch_size = 32\n",
    "kernel_size = 5\n",
    "filters = 16\n",
    "latent_dim = 2\n",
    "epochs = 1000\n",
    "\n",
    "# reparameterization\n",
    "def sampling(args): \n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# encoder\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "\n",
    "filters = filters* 2\n",
    "x = Conv2D(filters=filters,kernel_size=(1, 50),strides=(1,25),)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\n",
    "filters = filters* 2\n",
    "x = Conv2D(filters=filters,kernel_size=(22, 1),)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "z_log_var = z_log_var + 1e-8 \n",
    "\n",
    "# reparameterization\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var]) \n",
    "\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder \n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "x = Conv2DTranspose(filters=filters,kernel_size=(22, 1),activation='relu',)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "filters = filters// 2\n",
    "x = Conv2DTranspose(filters=filters,kernel_size=(1, 50),activation='relu',strides=(1,25))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "filters = filters// 2\n",
    "outputs = Conv2DTranspose(filters=1,kernel_size=kernel_size,padding='same',name='decoder_output')(x)\n",
    "\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model (merging encoder and decoder)\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b677bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Custom loss function \n",
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "\n",
    "reconstruction_loss *= input_shape[0] * input_shape[1]\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "\n",
    "#optimizer\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.5, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "# compiling vae\n",
    "vae.compile(optimizer=optimizer, loss=None)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbce45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping callback\n",
    "callbacks = EarlyStopping(monitor = 'val_loss',\n",
    "                          mode='min',\n",
    "                          patience =50,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit vae model\n",
    "history = vae.fit(X_train,X_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, X_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73734deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss curves\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('loss curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D plot of the classes in latent space\n",
    "z_m, _, _ = encoder.predict(X_test,batch_size=batch_size)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(z_m[:, 0], z_m[:, 1], c=X_test[:,0,0,0])\n",
    "plt.xlabel(\"z[0]\")\n",
    "plt.ylabel(\"z[1]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on validation data\n",
    "pred=vae.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observing generated signals\n",
    "plt.plot(X_test[0,:,:,0])\n",
    "plt.plot(pred[0,:,:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
